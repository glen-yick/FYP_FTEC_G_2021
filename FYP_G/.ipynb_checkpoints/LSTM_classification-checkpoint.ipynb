{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\gleny\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\gleny\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\gleny\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\gleny\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\gleny\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\gleny\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\gleny\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\gleny\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\gleny\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\gleny\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\gleny\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\gleny\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# multi-class classification with Keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1919, 1197)\n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = pd.read_csv(\"convertcsv_label.csv\", header=0, index_col=0)\n",
    "dataset = dataset.drop(['Date', 'Date.1', 'Date.2', 'Date.3'], axis=1)\n",
    "values = dataset.values\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "for i in range(1, 1914):\n",
    "    for j in range(1, 50):\n",
    "        values[i][j] -= values[0][j]\n",
    "for k in range(1, 50):\n",
    "    values[0][k] = 0\n",
    "\n",
    "days = 20\n",
    "features = 57\n",
    "obs = days * features\n",
    "\n",
    "# Normalize or not Normalize\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# values = scaler.fit_transform(values)\n",
    "\n",
    "\n",
    "reframed = series_to_supervised(values, days, 1)\n",
    "reframed = reframed.values\n",
    "np.savetxt(\"foo2.csv\", reframed, delimiter=\",\")\n",
    "print(reframed.shape)\n",
    "Y = reframed[:, -features]\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "print(dummy_y)\n",
    "# print(values)\n",
    "np.savetxt(\"foo.csv\", dummy_y, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 20, 57)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "You can change the n_train_hours from 0.85 * 1938 or 0.9 or 0.8, whatever you like\n",
    "\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\"\"\"\n",
    "n_train_hours = 1647  # 0.8*1938\n",
    "train_X = reframed[:n_train_hours, :obs]  # 1647, 1140\n",
    "train_Y = dummy_y[:n_train_hours, :]\n",
    "test_X = reframed[n_train_hours:, :obs]  # 248, 1140\n",
    "test_Y = dummy_y[n_train_hours:, :]\n",
    "\n",
    "train_X = train_X.reshape((train_X.shape[0], days, features))\n",
    "test_X = test_X.reshape((test_X.shape[0], days, features))\n",
    "print(test_X.shape)\n",
    "# np.savetxt(\"foo.csv\", train_X, delimiter=\",\")\n",
    "\n",
    "edit = []\n",
    "\n",
    "# covert 3d to one domension\n",
    "\n",
    "for i in dummy_y:\n",
    "    for k,v in enumerate(i):\n",
    "        if (v == 1):\n",
    "            edit.append(k)\n",
    "\n",
    "\n",
    "train_Y = edit[:n_train_hours]\n",
    "test_Y = edit[n_train_hours:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.17924528 0.38178025 5.33009709]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gleny\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2], y=[1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(edit)\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# oversampling the buy and sell signal\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(train_Y),\n",
    "                                                 train_Y)\n",
    "\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gleny\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\gleny\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1647 samples, validate on 272 samples\n",
      "Epoch 1/50\n",
      " - 5s - loss: 0.5102 - accuracy: 0.8658 - val_loss: 0.5346 - val_accuracy: 0.8603\n",
      "Epoch 2/50\n",
      " - 5s - loss: 0.4754 - accuracy: 0.8731 - val_loss: 0.5116 - val_accuracy: 0.8603\n",
      "Epoch 3/50\n",
      " - 4s - loss: 0.4728 - accuracy: 0.8731 - val_loss: 0.5141 - val_accuracy: 0.8603\n",
      "Epoch 4/50\n",
      " - 5s - loss: 0.4696 - accuracy: 0.8731 - val_loss: 0.5131 - val_accuracy: 0.8603\n",
      "Epoch 5/50\n",
      " - 5s - loss: 0.4737 - accuracy: 0.8731 - val_loss: 0.5252 - val_accuracy: 0.8603\n",
      "Epoch 6/50\n",
      " - 5s - loss: 0.4734 - accuracy: 0.8731 - val_loss: 0.5079 - val_accuracy: 0.8603\n",
      "Epoch 7/50\n",
      " - 5s - loss: 0.4700 - accuracy: 0.8731 - val_loss: 0.5113 - val_accuracy: 0.8603\n",
      "Epoch 8/50\n",
      " - 5s - loss: 0.4679 - accuracy: 0.8731 - val_loss: 0.5138 - val_accuracy: 0.8603\n",
      "Epoch 9/50\n",
      " - 5s - loss: 0.4698 - accuracy: 0.8731 - val_loss: 0.5106 - val_accuracy: 0.8603\n",
      "Epoch 10/50\n",
      " - 5s - loss: 0.4667 - accuracy: 0.8731 - val_loss: 0.5114 - val_accuracy: 0.8603\n",
      "Epoch 11/50\n",
      " - 5s - loss: 0.4675 - accuracy: 0.8731 - val_loss: 0.5149 - val_accuracy: 0.8603\n",
      "Epoch 12/50\n",
      " - 4s - loss: 0.4660 - accuracy: 0.8731 - val_loss: 0.5157 - val_accuracy: 0.8603\n",
      "Epoch 13/50\n",
      " - 4s - loss: 0.4642 - accuracy: 0.8731 - val_loss: 0.5229 - val_accuracy: 0.8603\n",
      "Epoch 14/50\n",
      " - 4s - loss: 0.4694 - accuracy: 0.8731 - val_loss: 0.5175 - val_accuracy: 0.8603\n",
      "Epoch 15/50\n",
      " - 4s - loss: 0.4662 - accuracy: 0.8731 - val_loss: 0.5188 - val_accuracy: 0.8603\n",
      "Epoch 16/50\n",
      " - 4s - loss: 0.4653 - accuracy: 0.8731 - val_loss: 0.5239 - val_accuracy: 0.8603\n",
      "Epoch 17/50\n",
      " - 4s - loss: 0.4649 - accuracy: 0.8731 - val_loss: 0.5168 - val_accuracy: 0.8603\n",
      "Epoch 18/50\n",
      " - 4s - loss: 0.4625 - accuracy: 0.8731 - val_loss: 0.5194 - val_accuracy: 0.8603\n",
      "Epoch 19/50\n",
      " - 5s - loss: 0.4636 - accuracy: 0.8731 - val_loss: 0.5220 - val_accuracy: 0.8603\n",
      "Epoch 20/50\n",
      " - 4s - loss: 0.4644 - accuracy: 0.8731 - val_loss: 0.5208 - val_accuracy: 0.8603\n",
      "Epoch 21/50\n",
      " - 4s - loss: 0.4616 - accuracy: 0.8731 - val_loss: 0.5363 - val_accuracy: 0.8603\n",
      "Epoch 22/50\n",
      " - 4s - loss: 0.4630 - accuracy: 0.8731 - val_loss: 0.5311 - val_accuracy: 0.8603\n",
      "Epoch 23/50\n",
      " - 4s - loss: 0.4667 - accuracy: 0.8731 - val_loss: 0.5282 - val_accuracy: 0.8603\n",
      "Epoch 24/50\n",
      " - 4s - loss: 0.4595 - accuracy: 0.8731 - val_loss: 0.5259 - val_accuracy: 0.8603\n",
      "Epoch 25/50\n",
      " - 4s - loss: 0.4609 - accuracy: 0.8731 - val_loss: 0.5259 - val_accuracy: 0.8603\n",
      "Epoch 26/50\n",
      " - 4s - loss: 0.4565 - accuracy: 0.8731 - val_loss: 0.5296 - val_accuracy: 0.8603\n",
      "Epoch 27/50\n",
      " - 4s - loss: 0.4571 - accuracy: 0.8731 - val_loss: 0.5406 - val_accuracy: 0.8603\n",
      "Epoch 28/50\n",
      " - 4s - loss: 0.4573 - accuracy: 0.8731 - val_loss: 0.5507 - val_accuracy: 0.8603\n",
      "Epoch 29/50\n",
      " - 4s - loss: 0.4581 - accuracy: 0.8731 - val_loss: 0.5470 - val_accuracy: 0.8603\n",
      "Epoch 30/50\n",
      " - 4s - loss: 0.4550 - accuracy: 0.8731 - val_loss: 0.5479 - val_accuracy: 0.8603\n",
      "Epoch 31/50\n",
      " - 4s - loss: 0.4544 - accuracy: 0.8731 - val_loss: 0.5446 - val_accuracy: 0.8603\n",
      "Epoch 32/50\n",
      " - 4s - loss: 0.4534 - accuracy: 0.8731 - val_loss: 0.5439 - val_accuracy: 0.8603\n",
      "Epoch 33/50\n",
      " - 4s - loss: 0.4490 - accuracy: 0.8731 - val_loss: 0.5614 - val_accuracy: 0.8603\n",
      "Epoch 34/50\n",
      " - 4s - loss: 0.4470 - accuracy: 0.8731 - val_loss: 0.5511 - val_accuracy: 0.8603\n",
      "Epoch 35/50\n",
      " - 4s - loss: 0.4494 - accuracy: 0.8731 - val_loss: 0.5590 - val_accuracy: 0.8603\n",
      "Epoch 36/50\n",
      " - 4s - loss: 0.4480 - accuracy: 0.8737 - val_loss: 0.5720 - val_accuracy: 0.8603\n",
      "Epoch 37/50\n",
      " - 4s - loss: 0.4442 - accuracy: 0.8737 - val_loss: 0.5644 - val_accuracy: 0.8603\n",
      "Epoch 38/50\n",
      " - 4s - loss: 0.4450 - accuracy: 0.8737 - val_loss: 0.5726 - val_accuracy: 0.8603\n",
      "Epoch 39/50\n",
      " - 4s - loss: 0.4421 - accuracy: 0.8737 - val_loss: 0.5706 - val_accuracy: 0.8603\n",
      "Epoch 40/50\n",
      " - 4s - loss: 0.4406 - accuracy: 0.8737 - val_loss: 0.5642 - val_accuracy: 0.8603\n",
      "Epoch 41/50\n",
      " - 4s - loss: 0.4445 - accuracy: 0.8737 - val_loss: 0.5813 - val_accuracy: 0.8603\n",
      "Epoch 42/50\n",
      " - 4s - loss: 0.4345 - accuracy: 0.8743 - val_loss: 0.5804 - val_accuracy: 0.8603\n",
      "Epoch 43/50\n",
      " - 4s - loss: 0.4332 - accuracy: 0.8743 - val_loss: 0.5764 - val_accuracy: 0.8603\n",
      "Epoch 44/50\n",
      " - 4s - loss: 0.4362 - accuracy: 0.8749 - val_loss: 0.5969 - val_accuracy: 0.8603\n",
      "Epoch 45/50\n",
      " - 4s - loss: 0.4366 - accuracy: 0.8755 - val_loss: 0.5896 - val_accuracy: 0.8529\n",
      "Epoch 46/50\n",
      " - 4s - loss: 0.4281 - accuracy: 0.8755 - val_loss: 0.5861 - val_accuracy: 0.8456\n",
      "Epoch 47/50\n",
      " - 4s - loss: 0.4316 - accuracy: 0.8755 - val_loss: 0.5999 - val_accuracy: 0.8456\n",
      "Epoch 48/50\n",
      " - 4s - loss: 0.4270 - accuracy: 0.8755 - val_loss: 0.6046 - val_accuracy: 0.8603\n",
      "Epoch 49/50\n",
      " - 4s - loss: 0.4254 - accuracy: 0.8761 - val_loss: 0.5957 - val_accuracy: 0.8603\n",
      "Epoch 50/50\n",
      " - 4s - loss: 0.4181 - accuracy: 0.8792 - val_loss: 0.6175 - val_accuracy: 0.8566\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(256, return_sequences=False))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=3))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.fit(train_X, train_Y, epochs=50, batch_size=44, validation_data=(test_X, test_Y), verbose=2, class_weight = class_weights)\n",
    "# test_mse = model.evaluate(test_X, test_Y, verbose=1)\n",
    "predicted_values = model.predict(test_X)\n",
    "# print(predicted_values)\n",
    "\n",
    "predict_from_test = pd.DataFrame(predicted_values, columns=['sell', 'stay', 'buy'])\n",
    "predict_from_test.to_csv(\"prediction.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version            \n",
      "---------------------------------- -------------------\n",
      "absl-py                            0.10.0             \n",
      "alabaster                          0.7.12             \n",
      "anaconda-client                    1.7.2              \n",
      "anaconda-navigator                 1.9.12             \n",
      "anaconda-project                   0.8.3              \n",
      "argh                               0.26.2             \n",
      "asn1crypto                         1.3.0              \n",
      "astor                              0.8.1              \n",
      "astroid                            2.3.3              \n",
      "astropy                            4.0                \n",
      "atomicwrites                       1.3.0              \n",
      "attrs                              19.3.0             \n",
      "autopep8                           1.4.4              \n",
      "Babel                              2.8.0              \n",
      "backcall                           0.1.0              \n",
      "backports.functools-lru-cache      1.6.1              \n",
      "backports.shutil-get-terminal-size 1.0.0              \n",
      "backports.tempfile                 1.0                \n",
      "backports.weakref                  1.0.post1          \n",
      "bcrypt                             3.1.7              \n",
      "beautifulsoup4                     4.8.2              \n",
      "bitarray                           1.2.1              \n",
      "bkcharts                           0.2                \n",
      "bleach                             3.1.0              \n",
      "bokeh                              1.4.0              \n",
      "boto                               2.49.0             \n",
      "Bottleneck                         1.3.2              \n",
      "catboost                           0.24.3             \n",
      "certifi                            2019.11.28         \n",
      "cffi                               1.14.0             \n",
      "chardet                            3.0.4              \n",
      "Click                              7.0                \n",
      "cloudpickle                        1.3.0              \n",
      "clyent                             1.2.2              \n",
      "colorama                           0.4.3              \n",
      "comtypes                           1.1.7              \n",
      "conda                              4.9.2              \n",
      "conda-build                        3.18.11            \n",
      "conda-package-handling             1.6.0              \n",
      "conda-verify                       3.4.2              \n",
      "contextlib2                        0.6.0.post1        \n",
      "cryptography                       2.8                \n",
      "cycler                             0.10.0             \n",
      "Cython                             0.29.15            \n",
      "cytoolz                            0.10.1             \n",
      "dask                               2.11.0             \n",
      "decorator                          4.4.1              \n",
      "defusedxml                         0.6.0              \n",
      "diff-match-patch                   20181111           \n",
      "distributed                        2.11.0             \n",
      "docutils                           0.16               \n",
      "entrypoints                        0.3                \n",
      "et-xmlfile                         1.0.1              \n",
      "fastcache                          1.1.0              \n",
      "filelock                           3.0.12             \n",
      "flake8                             3.7.9              \n",
      "Flask                              1.1.1              \n",
      "fsspec                             0.6.2              \n",
      "futu-api                           3.21.0             \n",
      "future                             0.18.2             \n",
      "gast                               0.4.0              \n",
      "gevent                             1.4.0              \n",
      "glob2                              0.7                \n",
      "greenlet                           0.4.15             \n",
      "grpcio                             1.27.2             \n",
      "h5py                               2.10.0             \n",
      "HeapDict                           1.0.1              \n",
      "html5lib                           1.0.1              \n",
      "hypothesis                         5.5.4              \n",
      "idna                               2.8                \n",
      "imageio                            2.6.1              \n",
      "imagesize                          1.2.0              \n",
      "imbalanced-learn                   0.7.0              \n",
      "importlib-metadata                 2.0.0              \n",
      "intervaltree                       3.0.2              \n",
      "ipykernel                          5.1.4              \n",
      "ipython                            7.12.0             \n",
      "ipython-genutils                   0.2.0              \n",
      "ipywidgets                         7.5.1              \n",
      "isort                              4.3.21             \n",
      "itsdangerous                       1.1.0              \n",
      "jdcal                              1.4.1              \n",
      "jedi                               0.14.1             \n",
      "Jinja2                             2.11.1             \n",
      "joblib                             0.14.1             \n",
      "json5                              0.9.1              \n",
      "jsonschema                         3.2.0              \n",
      "jupyter                            1.0.0              \n",
      "jupyter-client                     5.3.4              \n",
      "jupyter-console                    6.1.0              \n",
      "jupyter-core                       4.6.1              \n",
      "jupyterlab                         1.2.6              \n",
      "jupyterlab-server                  1.0.6              \n",
      "Keras                              2.3.1              \n",
      "Keras-Applications                 1.0.8              \n",
      "Keras-Preprocessing                1.1.0              \n",
      "keyring                            21.1.0             \n",
      "kiwisolver                         1.1.0              \n",
      "lazy-object-proxy                  1.4.3              \n",
      "libarchive-c                       2.8                \n",
      "lightgbm                           3.1.0              \n",
      "llvmlite                           0.31.0             \n",
      "locket                             0.2.0              \n",
      "lxml                               4.6.2              \n",
      "Markdown                           3.3.2              \n",
      "MarkupSafe                         1.1.1              \n",
      "matplotlib                         3.1.3              \n",
      "mccabe                             0.6.1              \n",
      "menuinst                           1.4.16             \n",
      "mistune                            0.8.4              \n",
      "mkl-fft                            1.0.15             \n",
      "mkl-random                         1.1.0              \n",
      "mkl-service                        2.3.0              \n",
      "mock                               4.0.1              \n",
      "more-itertools                     8.2.0              \n",
      "mpmath                             1.1.0              \n",
      "msgpack                            0.6.1              \n",
      "multipledispatch                   0.6.0              \n",
      "multitasking                       0.0.9              \n",
      "mysql-connector-python             8.0.23             \n",
      "navigator-updater                  0.2.1              \n",
      "nbconvert                          5.6.1              \n",
      "nbformat                           5.0.4              \n",
      "networkx                           2.4                \n",
      "nltk                               3.4.5              \n",
      "nose                               1.3.7              \n",
      "notebook                           6.0.3              \n",
      "numba                              0.48.0             \n",
      "numexpr                            2.7.1              \n",
      "numpy                              1.18.1             \n",
      "numpydoc                           0.9.2              \n",
      "olefile                            0.46               \n",
      "openpyxl                           3.0.3              \n",
      "packaging                          20.1               \n",
      "pandas                             1.0.1              \n",
      "pandas-datareader                  0.9.0              \n",
      "pandas-ta                          0.2.23b0           \n",
      "pandocfilters                      1.4.2              \n",
      "paramiko                           2.7.1              \n",
      "parso                              0.5.2              \n",
      "partd                              1.1.0              \n",
      "path                               13.1.0             \n",
      "pathlib2                           2.3.5              \n",
      "pathtools                          0.1.2              \n",
      "patsy                              0.5.1              \n",
      "pep8                               1.7.1              \n",
      "pexpect                            4.8.0              \n",
      "pickleshare                        0.7.5              \n",
      "Pillow                             7.0.0              \n",
      "pip                                20.0.2             \n",
      "pkginfo                            1.5.0.1            \n",
      "plotly                             4.8.0              \n",
      "pluggy                             0.13.1             \n",
      "ply                                3.11               \n",
      "prometheus-client                  0.7.1              \n",
      "prompt-toolkit                     3.0.3              \n",
      "protobuf                           3.13.0             \n",
      "psutil                             5.6.7              \n",
      "py                                 1.8.1              \n",
      "pycodestyle                        2.5.0              \n",
      "pycosat                            0.6.3              \n",
      "pycparser                          2.19               \n",
      "pycrypto                           2.6.1              \n",
      "pycryptodome                       3.9.7              \n",
      "pycurl                             7.43.0.5           \n",
      "pydocstyle                         4.0.1              \n",
      "pyflakes                           2.1.1              \n",
      "Pygments                           2.5.2              \n",
      "pylint                             2.4.4              \n",
      "PyNaCl                             1.3.0              \n",
      "pyodbc                             4.0.0-unsupported  \n",
      "pyOpenSSL                          19.1.0             \n",
      "pyparsing                          2.4.6              \n",
      "pyreadline                         2.1                \n",
      "pyrsistent                         0.15.7             \n",
      "PySocks                            1.7.1              \n",
      "pytest                             5.3.5              \n",
      "pytest-arraydiff                   0.3                \n",
      "pytest-astropy                     0.8.0              \n",
      "pytest-astropy-header              0.1.2              \n",
      "pytest-doctestplus                 0.5.0              \n",
      "pytest-openfiles                   0.4.0              \n",
      "pytest-remotedata                  0.3.2              \n",
      "python-dateutil                    2.8.1              \n",
      "python-jsonrpc-server              0.3.4              \n",
      "python-language-server             0.31.7             \n",
      "pytz                               2019.3             \n",
      "PyWavelets                         1.1.1              \n",
      "pywin32                            227                \n",
      "pywin32-ctypes                     0.2.0              \n",
      "pywinpty                           0.5.7              \n",
      "PyYAML                             5.3                \n",
      "pyzmq                              18.1.1             \n",
      "QDarkStyle                         2.8                \n",
      "QtAwesome                          0.6.1              \n",
      "qtconsole                          4.6.0              \n",
      "QtPy                               1.9.0              \n",
      "requests                           2.22.0             \n",
      "retrying                           1.3.3              \n",
      "rope                               0.16.0             \n",
      "Rtree                              0.9.3              \n",
      "ruamel-yaml                        0.15.87            \n",
      "schedule                           0.6.0              \n",
      "scikit-image                       0.16.2             \n",
      "scikit-learn                       0.23.2             \n",
      "scipy                              1.4.1              \n",
      "seaborn                            0.10.0             \n",
      "Send2Trash                         1.5.0              \n",
      "setuptools                         45.2.0.post20200210\n",
      "simplegeneric                      0.8.1              \n",
      "simplejson                         3.17.0             \n",
      "singledispatch                     3.4.0.3            \n",
      "six                                1.14.0             \n",
      "snowballstemmer                    2.0.0              \n",
      "sortedcollections                  1.1.2              \n",
      "sortedcontainers                   2.1.0              \n",
      "soupsieve                          1.9.5              \n",
      "Sphinx                             2.4.0              \n",
      "sphinxcontrib-applehelp            1.0.1              \n",
      "sphinxcontrib-devhelp              1.0.1              \n",
      "sphinxcontrib-htmlhelp             1.0.2              \n",
      "sphinxcontrib-jsmath               1.0.1              \n",
      "sphinxcontrib-qthelp               1.0.2              \n",
      "sphinxcontrib-serializinghtml      1.1.3              \n",
      "sphinxcontrib-websupport           1.2.0              \n",
      "spyder                             4.0.1              \n",
      "spyder-kernels                     1.8.1              \n",
      "SQLAlchemy                         1.3.13             \n",
      "statsmodels                        0.11.0             \n",
      "sympy                              1.5.1              \n",
      "ta                                 0.7.0              \n",
      "tables                             3.6.1              \n",
      "tblib                              1.6.0              \n",
      "tensorboard                        1.14.0             \n",
      "tensorflow                         1.14.0             \n",
      "tensorflow-estimator               1.14.0             \n",
      "termcolor                          1.1.0              \n",
      "terminado                          0.8.3              \n",
      "testpath                           0.4.4              \n",
      "threadpoolctl                      2.1.0              \n",
      "toolz                              0.10.0             \n",
      "torch                              1.5.0              \n",
      "torchvision                        0.6.0              \n",
      "tornado                            6.0.3              \n",
      "tqdm                               4.42.1             \n",
      "traitlets                          4.3.3              \n",
      "ujson                              1.35               \n",
      "unicodecsv                         0.14.1             \n",
      "urllib3                            1.25.8             \n",
      "watchdog                           0.10.2             \n",
      "wcwidth                            0.1.8              \n",
      "webencodings                       0.5.1              \n",
      "Werkzeug                           1.0.0              \n",
      "wheel                              0.34.2             \n",
      "widgetsnbextension                 3.5.1              \n",
      "win-inet-pton                      1.1.0              \n",
      "win-unicode-console                0.5                \n",
      "wincertstore                       0.2                \n",
      "wrapt                              1.11.2             \n",
      "xgboost                            0.90               \n",
      "xlrd                               1.2.0              \n",
      "XlsxWriter                         1.2.7              \n",
      "xlwings                            0.17.1             \n",
      "xlwt                               1.3.0              \n",
      "xmltodict                          0.12.0             \n",
      "yahoo-finance                      1.4.0              \n",
      "yapf                               0.28.0             \n",
      "yfinance                           0.1.55             \n",
      "zict                               1.0.0              \n",
      "zipp                               2.2.0              \n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the best model\n",
    "tuple_objects = (model, train_X, train_Y)\n",
    "pickle.dump(tuple_objects, open(\"picklefile.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<keras.engine.sequential.Sequential at 0x1b12a3a3808>,\n",
       " array([[[ 1.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  2.37      ,  1.5       , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  2.9099998 ,  1.6000004 , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ...,\n",
       "         [ 1.        , -1.0100002 , -1.3499994 , ...,  0.        ,\n",
       "           0.        ,  1.        ],\n",
       "         [ 1.        , -1.0100002 , -1.3499994 , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  1.0499992 , -0.19999981, ...,  0.        ,\n",
       "          -1.        , -1.        ]],\n",
       " \n",
       "        [[ 0.        ,  2.37      ,  1.5       , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  2.9099998 ,  1.6000004 , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  1.8599997 ,  0.95000076, ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ...,\n",
       "         [ 1.        , -1.0100002 , -1.3499994 , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  1.0499992 , -0.19999981, ...,  0.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.        ,  2.08      ,  0.9000006 , ...,  0.        ,\n",
       "          -1.        , -1.        ]],\n",
       " \n",
       "        [[ 0.        ,  2.9099998 ,  1.6000004 , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  1.8599997 ,  0.95000076, ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [-1.        ,  6.6799994 ,  3.75      , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ...,\n",
       "         [ 0.        ,  1.0499992 , -0.19999981, ...,  0.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.        ,  2.08      ,  0.9000006 , ...,  0.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        ,  0.35999966,  0.6000004 , ...,  0.        ,\n",
       "          -1.        ,  0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.        ,  6.669999  ,  4.925001  , ...,  0.        ,\n",
       "          -1.        ,  1.        ],\n",
       "         [-1.        ,  7.3499994 ,  5.625     , ...,  0.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.        ,  5.0199995 ,  4.175001  , ...,  0.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.        ,  3.6499996 ,  3.3250008 , ...,  0.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.        ,  3.7599993 ,  3.5249996 , ...,  0.        ,\n",
       "          -1.        ,  1.        ],\n",
       "         [ 0.        ,  4.909999  ,  4.125     , ...,  0.        ,\n",
       "          -1.        , -1.        ]],\n",
       " \n",
       "        [[-1.        ,  7.3499994 ,  5.625     , ...,  0.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.        ,  5.0199995 ,  4.175001  , ...,  0.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.        ,  3.96      ,  3.375     , ...,  0.        ,\n",
       "          -1.        ,  1.        ],\n",
       "         ...,\n",
       "         [ 0.        ,  3.7599993 ,  3.5249996 , ...,  0.        ,\n",
       "          -1.        ,  1.        ],\n",
       "         [ 0.        ,  4.909999  ,  4.125     , ...,  0.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.        ,  3.9299994 ,  3.2250004 , ...,  0.        ,\n",
       "          -1.        , -1.        ]],\n",
       " \n",
       "        [[ 0.        ,  5.0199995 ,  4.175001  , ...,  0.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.        ,  3.96      ,  3.375     , ...,  0.        ,\n",
       "          -1.        ,  1.        ],\n",
       "         [ 0.        ,  2.6899996 ,  2.625     , ...,  0.        ,\n",
       "          -1.        ,  1.        ],\n",
       "         ...,\n",
       "         [ 0.        ,  4.909999  ,  4.125     , ...,  0.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.        ,  3.9299994 ,  3.2250004 , ...,  0.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.        ,  6.249999  ,  4.675001  , ...,  1.        ,\n",
       "          -1.        ,  1.        ]]], dtype=float32),\n",
       " [1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  ...])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('51_profit_last272.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "predicted_values = data[0].predict(test_X)\n",
    "predict_from_test = pd.DataFrame(predicted_values, columns=['sell', 'stay', 'buy'])\n",
    "predict_from_test.to_csv(\"pickle_prediction.csv\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
